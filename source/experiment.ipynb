{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:55:44.230257Z",
     "start_time": "2024-08-17T15:55:39.496854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:55:44.256891Z",
     "start_time": "2024-08-17T15:55:44.231261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom imports\n",
    "from config import get_config\n",
    "from dataset import DataSet, prepare_interaction_pairs, create_tf_dataset\n",
    "from models.lstm_model import build_lstm_model\n",
    "from models.lstm_attention_model import build_lstm_attention_model\n",
    "from models.transformer_model import build_transformer_model"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:55:44.266415Z",
     "start_time": "2024-08-17T15:55:44.260868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 1: Define CI score function\n",
    "def ci_score(y_true, y_pred):\n",
    "    ind = np.argsort(y_true)\n",
    "    y_true = y_true[ind]\n",
    "    y_pred = y_pred[ind]\n",
    "    i = len(y_true)-1\n",
    "    j = i-1\n",
    "    z = 0\n",
    "    S = 0\n",
    "    while i > 0:\n",
    "        while j >= 0:\n",
    "            if y_true[i] > y_true[j]:\n",
    "                z = z+1\n",
    "                if y_pred[i] > y_pred[j]:\n",
    "                    S = S + 1\n",
    "            j = j - 1\n",
    "        i = i - 1\n",
    "        j = i-1\n",
    "    ci = S/z\n",
    "    return ci\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:55:45.480385Z",
     "start_time": "2024-08-17T15:55:45.470481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2: Define custom callback with tqdm\n",
    "class TqdmCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs, metrics=['loss', 'val_loss']):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.metrics = metrics\n",
    "        self.tqdm_outer = None\n",
    "        self.tqdm_inner = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.tqdm_outer = tqdm(total=self.epochs, desc='Epochs', position=0)\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.tqdm_inner = tqdm(total=self.params['steps'], desc=f'Epoch {epoch+1}/{self.epochs}', position=1, leave=False)\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.tqdm_inner.update()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.tqdm_outer.update()\n",
    "        self.tqdm_inner.close()\n",
    "        metrics_str = ' - '.join([f'{m}: {logs[m]:.4f}' for m in self.metrics if m in logs])\n",
    "        self.tqdm_outer.set_postfix_str(metrics_str)\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.tqdm_outer.close()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:55:46.300015Z",
     "start_time": "2024-08-17T15:55:46.281175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiment(config, dataset_type):\n",
    "    print(f\"\\nRunning experiment for {dataset_type} dataset\")\n",
    "    \n",
    "    if dataset_type == 'davis':\n",
    "        dataset = DataSet(config['davis_path'], config['problem_type'], config['max_seq_len'], \n",
    "                          config['max_smi_len'], 'davis', config['davis_convert_to_log'])\n",
    "    else:\n",
    "        dataset = DataSet(config['kiba_path'], config['problem_type'], config['max_seq_len'], \n",
    "                          config['max_smi_len'], 'kiba', config['kiba_convert_to_log'])\n",
    "\n",
    "    XD, XT, Y, label_row_inds, label_col_inds, _, _ = dataset.get_data()\n",
    "\n",
    "    # Update config with dataset-specific alphabet sizes\n",
    "    config['charsmiset_size'] = dataset.charsmiset_size\n",
    "    config['charseqset_size'] = dataset.charseqset_size\n",
    "\n",
    "    models = {\n",
    "        'LSTM': build_lstm_model,\n",
    "        'LSTM with Attention': build_lstm_attention_model,\n",
    "        'Transformer': build_transformer_model\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for model_name, model_builder in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        model_ci_scores = []\n",
    "        model_rmse_scores = []\n",
    "        \n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(label_row_inds)):\n",
    "            print(f\"Fold {fold + 1}/5\")\n",
    "            \n",
    "            train_drug_data, train_target_data, train_affinity = prepare_interaction_pairs(\n",
    "                XD, XT, Y, label_row_inds[train_index], label_col_inds[train_index])\n",
    "            \n",
    "            val_drug_data, val_target_data, val_affinity = prepare_interaction_pairs(\n",
    "                XD, XT, Y, label_row_inds[val_index], label_col_inds[val_index])\n",
    "            \n",
    "            train_dataset = create_tf_dataset(train_drug_data, train_target_data, train_affinity, config['batch_size'])\n",
    "            val_dataset = create_tf_dataset(val_drug_data, val_target_data, val_affinity, config['batch_size'], shuffle=False)\n",
    "            \n",
    "            model = model_builder(config)\n",
    "            \n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            tqdm_callback = TqdmCallback(epochs=config['num_epoch'])\n",
    "            \n",
    "            start_time = time.time()\n",
    "            history = model.fit(\n",
    "                train_dataset,\n",
    "                epochs=config['num_epoch'],\n",
    "                validation_data=val_dataset,\n",
    "                callbacks=[early_stopping, tqdm_callback],\n",
    "                verbose=0\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            \n",
    "            val_predictions = model.predict(val_dataset, verbose=0)\n",
    "            val_ci = ci_score(val_affinity, val_predictions.flatten())\n",
    "            val_rmse = tf.keras.metrics.RootMeanSquaredError()(val_affinity, val_predictions.flatten()).numpy()\n",
    "            \n",
    "            model_ci_scores.append(val_ci)\n",
    "            model_rmse_scores.append(val_rmse)\n",
    "            \n",
    "            print(f\"Fold {fold + 1} - CI: {val_ci:.4f}, RMSE: {val_rmse:.4f}, Training Time: {training_time:.2f} seconds\")\n",
    "        \n",
    "        avg_ci = np.mean(model_ci_scores)\n",
    "        avg_rmse = np.mean(model_rmse_scores)\n",
    "        results[model_name] = {'CI': avg_ci, 'RMSE': avg_rmse}\n",
    "        \n",
    "        print(f\"{model_name} - Average CI: {avg_ci:.4f}, Average RMSE: {avg_rmse:.4f}\")\n",
    "\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-17T15:55:47.117266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 4: Run experiments for both datasets\n",
    "config = get_config()\n",
    "davis_results = run_experiment(config, 'davis')\n",
    "kiba_results = run_experiment(config, 'kiba')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment for davis dataset\n",
      "Reading davis dataset from ../data/davis/\n",
      "Parsing davis dataset\n",
      "\n",
      "Training LSTM...\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\miniconda3\\envs\\BioInf-Final\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6087344118c94a3e9e3f1f482c7853e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1/100:   0%|          | 0/94 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9fff50a6d01424a9a35b4d7ed5fcdc1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 5: Compare results\n",
    "def print_results(results, dataset_name):\n",
    "    print(f\"\\nFinal Results for {dataset_name} dataset:\")\n",
    "    for model_name, scores in results.items():\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  CI: {scores['CI']:.4f}\")\n",
    "        print(f\"  RMSE: {scores['RMSE']:.4f}\")\n",
    "\n",
    "print_results(davis_results, \"Davis\")\n",
    "print_results(kiba_results, \"KIBA\")\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 6: Visualize results\n",
    "def plot_results(davis_results, kiba_results):\n",
    "    models = list(davis_results.keys())\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.2\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "    # CI Score plot\n",
    "    davis_ci = [davis_results[model]['CI'] for model in models]\n",
    "    kiba_ci = [kiba_results[model]['CI'] for model in models]\n",
    "\n",
    "    ax1.bar(x - width/2, davis_ci, width, label='Davis', color='b', alpha=0.7)\n",
    "    ax1.bar(x + width/2, kiba_ci, width, label='KIBA', color='r', alpha=0.7)\n",
    "    ax1.set_ylabel('CI Score')\n",
    "    ax1.set_title('CI Score Comparison')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "\n",
    "    # RMSE plot\n",
    "    davis_rmse = [davis_results[model]['RMSE'] for model in models]\n",
    "    kiba_rmse = [kiba_results[model]['RMSE'] for model in models]\n",
    "\n",
    "    ax2.bar(x - width/2, davis_rmse, width, label='Davis', color='b', alpha=0.7)\n",
    "    ax2.bar(x + width/2, kiba_rmse, width, label='KIBA', color='r', alpha=0.7)\n",
    "    ax2.set_ylabel('RMSE')\n",
    "    ax2.set_title('RMSE Comparison')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_results(davis_results, kiba_results)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 7: Compare with DeepDTA results\n",
    "deepdta_results = {\n",
    "    'Davis': {'CI': 0.878, 'MSE': 0.261},\n",
    "    'KIBA': {'CI': 0.863, 'MSE': 0.194}\n",
    "}\n",
    "\n",
    "def compare_with_deepdta(results, dataset_type):\n",
    "    print(f\"\\nComparison with DeepDTA for {dataset_type} dataset:\")\n",
    "    deepdta_ci = deepdta_results[dataset_type]['CI']\n",
    "    deepdta_mse = deepdta_results[dataset_type]['MSE']\n",
    "    print(f\"DeepDTA - CI: {deepdta_ci:.4f}, MSE: {deepdta_mse:.4f}\")\n",
    "\n",
    "    for model_name, scores in results.items():\n",
    "        ci_diff = scores['CI'] - deepdta_ci\n",
    "        rmse_diff = scores['RMSE'] - np.sqrt(deepdta_mse)\n",
    "        \n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  CI difference: {ci_diff:.4f} ({'better' if ci_diff > 0 else 'worse'})\")\n",
    "        print(f\"  RMSE difference: {rmse_diff:.4f} ({'worse' if rmse_diff > 0 else 'better'})\")\n",
    "\n",
    "compare_with_deepdta(davis_results, 'Davis')\n",
    "compare_with_deepdta(kiba_results, 'KIBA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
